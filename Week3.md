# 5.1 가설검정의 원리

4장에서 추론통계의 기본적인 구조와 신뢰구간에 대해 알아보았습니다. 이 장에서는 추론통계에 있어 또 하나의 중요한 원리인 가설검정을 살펴보도록 하겠습니다. 가설검정이란, 분석가가 세운 가설을 검증하기 위한 방법입니다. **가설검정에서는 p값(p-value)이라는 수치를 계산하여 가설을 지지하는지 여부를 판단합니다.**

p값은 과학 논문에 자주 등장하지만, 정의를 알기 어려워 제대로 이해하지 못한 채 사용하는 사람이 많고, 과학계의 다양한 문제를 일으키는 원인이 되곤 합니다. 여기에서는 예를 들어가면서 가능한 한 간단하게 가설검정의 원리와 p값을 설명하겠습니다.

---

## 확증적 자료분석과 탐색적 자료분석

가설검정을 이해하기 위한 첫 단계로, 데이터 분석의 두 가지 접근법을 알아보겠습니다.

* **확증적 자료분석 (Confirmatory Data Analysis)**: "신약에 효과가 있다"와 같이 미리 세운 가설을 검증하기 위해 실험이나 관찰을 통해 데이터를 수집하고 분석하는 방법입니다. 가설검정형 데이터 분석이라고도 합니다.

* **탐색적 자료분석 (Exploratory Data Analysis)**: 명확한 가설 없이 데이터를 다양하게 탐색하며 데이터의 특징이나 경향을 파악하고, 의미 있는 가설 후보를 찾는 방법입니다.

이 장에서는 주로 확증적 자료분석, 즉 가설검정에 대해 다룹니다.

---

## 가설검정이란?

> **가설검정 (Hypothesis Testing)**: 통계학에 기반을 둔 통계 가설을 검증하는 방법론. 과학계에서 데이터를 분석할 때 가장 많이 사용하는 방법이므로, 반드시 이해해야 합니다.

예를 들어, "신약이 고혈압에 효과가 있다"라는 가설을 검증하는 상황을 생각해 봅시다.

* **실험군 (Treatment Group)**: 신약을 투여한 집단
* **대조군 (Control Group)**: 위약(placebo)을 투여한 집단

두 집단의 혈압을 비교하여 신약의 효과를 통계적으로 분석합니다. 이처럼 비교 대상이 되는 2개(또는 그 이상)의 집단이 있다는 점이 가설검정의 가장 대표적인 특징입니다.

### 귀무가설과 대립가설

통계적 가설검정에서는 두 가지 상반된 가설을 세웁니다.

1.  **귀무가설 (Null Hypothesis, $H_0$)**: "차이가 없다", "효과가 없다"와 같이 우리가 **기각하고자 하는 가설**입니다. 일반적으로 현재까지 사실로 받아들여지는 주장을 의미합니다.
    * *예시: 신약은 효과가 없다.

2.  **대립가설 (Alternative Hypothesis, $H_A$ or $H_1$)**: "차이가 있다", "효과가 있다"와 같이 우리가 **주장하고 싶은 가설**입니다. 귀무가설이 기각될 때 채택됩니다.
    * *예시: 신약은 효과가 있다. 

가설검정은 귀무가설이 틀렸다는 증거를 데이터를 통해 보여줌으로써, 역설적으로 대립가설을 지지하는 논리적 흐름을 따릅니다.

*그림: 귀무가설이 기각되면 대립가설을 지지하게 된다.*

---

## 가설검정의 사고방식

### 모집단과 표본의 관계

우리가 정말로 알고 싶은 것은 모집단의 성질(예: 신약을 투여한 모집단 A의 평균 $\mu_A$와 위약을 투여한 모집단 B의 평균 $\mu_B$)이지만, 이를 직접 관찰하기는 불가능합니다. 따라서 우리는 모집단에서 추출한 표본(Sample)을 분석하여 모집단의 성질을 추정합니다.

이때 **표본오차(Sampling Error)**로 인해 모집단의 평균이 같더라도($\mu_A = \mu_B$), 표본평균($\bar{x}_A$와 $\bar{x}_B$)은 다르게 나타날 수 있습니다.

> **가설검정의 핵심 질문**: "관찰된 표본평균의 차이($\bar{x}_A - \bar{x}_B$)가 단순한 표본오차(우연) 때문에 발생한 것일까, 아니면 정말로 모집단 평균에 차이가 있기(약의 효과) 때문에 발생한 것일까?"

### 귀무가설이 옳은 세상 상상하기

이 질문에 답하기 위해, 우리는 먼저 **"귀무가설이 옳다"고 가정**합니다. 즉, 두 모집단의 평균이 동일한($\mu_A = \mu_B$) 가상의 세계를 상상하는 것입니다.

이 가상의 세계에서 표본을 반복해서 추출하면, 표본평균의 차이($\bar{x}_A - \bar{x}_B$)는 0을 중심으로 분포를 이룰 것입니다. 이를 **표본분포(Sampling Distribution)**라고 합니다. 대부분의 값은 0 근처에 나타나고, +10이나 -10처럼 극단적인 값은 매우 드물게 나타날 것입니다.

---

## p값이란?

> **p값 (p-value)의 정의**: 귀무가설이 옳다고 가정했을 때, 우리가 실제 데이터에서 관찰한 값 (예: 표본평균의 차이) 혹은 그보다 더 극단적인 값이 나타날 확률.

만약 실제로 얻은 데이터(예: $\bar{x}_A - \bar{x}_B = -10.9$)가 귀무가설이 옳은 가상의 세계에서는 매우 드물게(확률적으로 거의 일어나지 않는) 일어나는 일이라면, 우리는 "우리가 상상한 가상의 세계(귀무가설)가 틀렸다"라고 결론 내릴 수 있습니다.

p값은 이 '드문 정도'를 나타내는 척도이며, 0에서 1 사이의 값을 가집니다. **p값이 작을수록 귀무가설과 실제 데이터가 서로 맞지 않음**을 의미합니다.

### p값과 유의수준 $\alpha$를 이용한 가설 판정

p값을 이용해 귀무가설을 기각할지 말지 결정하는 기준이 필요한데, 이를 **유의수준(Significance Level, $\alpha$)**이라고 합니다. 과학계에서는 보통 $\alpha = 0.05$를 사용합니다.

* **p < 0.05**: 실제 데이터가 귀무가설 하에서 나타나기 매우 어려운 현상이라고 판단.
    * **귀무가설을 기각하고, 대립가설을 채택한다.**
    * "통계적으로 유의미한 차이가 있다 (statistically significant)"라고 표현한다.

* **p ≥ 0.05**: 실제 데이터가 귀무가설 하에서도 충분히 나타날 수 있는 현상이라고 판단.
    * **귀무가설을 기각할 수 없다.**
    * "통계적으로 유의미한 차이를 발견하지 못했다"라고 표현한다.

**주의할 점**: 귀무가설을 기각하지 못했다는 것이 "귀무가설이 맞다"는 뜻은 아닙니다. 단지 대립가설을 지지할 충분한 증거를 찾지 못했다는 의미일 뿐입니다.

# 5.2 가설검정 시행

가설검정의 원리를 이해했으니, 이제 실제로 p값을 어떻게 계산하는지 구체적인 방법을 살펴보겠습니다. 여러 가설검정 기법이 있지만, p값의 계산 방법은 서로 다릅니다. 하지만 모든 계산을 직접 할 필요는 없으며, R과 같은 통계 소프트웨어를 사용하면 쉽게 계산할 수 있습니다.

여기서는 가설검정의 개념을 더 깊이 이해하기 위해, 대표적인 방법인 **이표본 t-검정(two-sample t-test)**을 통해 p값을 계산하는 과정을 살펴보겠습니다.

---

## 가설검정의 구체적인 계산: 이표본 t-검정

두 집단의 평균을 비교하는 t-검정은 표본평균의 차이($\bar{x}_A - \bar{x}_B$)와 모집단평균의 차이($\mu_A - \mu_B$)의 관계에서 출발합니다. 이 둘의 차이, 즉 $(\bar{x}_A - \bar{x}_B) - (\mu_A - \mu_B)$는 정규분포를 근사적으로 따릅니다.

귀무가설이 옳다고 가정하면 $\mu_A - \mu_B = 0$ 이므로, 이 식은 $\bar{x}_A - \bar{x}_B$가 됩니다. 이 값을 표준오차로 나누어 표준화하면 **t값(t-statistic)**을 얻을 수 있으며, 이 t값은 **t-분포**를 따릅니다.

### t-검정의 계산 공식

모집단 평균의 차이에 대한 가설을 검정할 때 사용하는 t값은 다음과 같이 계산합니다.

> **t-통계량 (t-statistic)**
>
> $$
> t = \frac{(\bar{x}_A - \bar{x}_B)}{s\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}}
> $$
>
> 여기서 $\bar{x}$는 표본평균, $n$은 표본크기, $s$는 두 집단을 고려한 비편향표준편차(pooled standard deviation)를 의미합니다.

*비편향표준편차 $s$는 다음 공식으로 계산합니다.*
$$
s = \sqrt{\frac{(n_A - 1)s_A^2 + (n_B - 1)s_B^2}{n_A + n_B - 2}}
$$
*($s_A$와 $s_B$는 각 집단의 표준편차입니다.)*

---

## 기각역과 p값

t-분포에서 양쪽 끝의 잘 일어나지 않는 영역을 **기각역(rejection region)**이라고 부릅니다. 유의수준 $\alpha=0.05$인 양측검정에서는 양쪽 꼬리의 2.5%씩, 총 5%의 영역이 기각역이 됩니다.

실제 데이터로 계산한 t값이 이 기각역에 포함되면 p값은 0.05보다 작아지며, 귀무가설을 기각합니다.

> **p값**은 실제 데이터로 계산한 t값보다 더 극단적인 값이 나올 확률입니다. **양측검정(two-tailed test)**에서는 t값의 절대값보다 큰 영역의 확률을 양쪽에서 모두 더해 계산합니다.

*그림: 만약 실제 t값이 -2.3이라면, p값은 t분포에서 -2.3 이하일 확률과 +2.3 이상일 확률의 합입니다.*

### 신뢰구간과 가설검정의 관계

p값 계산과 신뢰구간 계산은 동전의 양면과 같은 관계입니다.
* **p값이 0.05보다 작다는 것**은 **모평균의 차이에 대한 95% 신뢰구간이 0을 포함하지 않는다**는 것과 동일한 의미입니다.
* **p값이 0.05보다 크다는 것**은 **모평균의 차이에 대한 95% 신뢰구간이 0을 포함한다**는 것과 동일한 의미입니다.

두 방법 모두 모집단과 표본의 차이를 다루는 동일한 원리를 기반으로 합니다.

---

## 가설검정의 구체적인 예

### 예 ①: 신약 효과가 통계적으로 유의미한 경우

- **데이터**:
  - 신약군: 142, 132, 127, 140, 142, 130, 126
  - 위약군: 145, 130, 150, 142, 145, 155, 148
- **계산 결과**:
  - $\bar{x}_A = 134.1$, $\bar{x}_B = 145.0$
  - 표본평균의 차이: $-10.9$
  - 비편향표준편차 $s = 7.44$
  - **t값 = -2.73**

계산된 t값(-2.73)을 t분포에 대입하여 p값을 계산하면 **$p = 0.018$** 입니다.


**결론**: p값(0.018)이 유의수준($\alpha=0.05$)보다 작으므로 **귀무가설을 기각**합니다. 따라서 "두 집단의 평균에 통계적으로 유의미한 차이가 있으며, 신약의 효과가 있다"고 판단할 수 있습니다.

### 예 ②: 신약 효과가 통계적으로 유의미하지 않은 경우

- **데이터**:
  - 신약군: 148, 138, 133, 146, 148, 136, 132
  - 위약군: 145, 130, 150, 142, 145, 155, 148
- **계산 결과**:
  - $\bar{x}_A = 140.1$, $\bar{x}_B = 145.0$
  - 표본평균의 차이: $-4.9$
  - **t값 = -1.22**

계산된 t값(-1.22)을 t분포에 대입하여 p값을 계산하면 **$p = 0.246$** 입니다.


**결론**: p값(0.246)이 유의수준($\alpha=0.05$)보다 크므로 **귀무가설을 기각하지 못합니다**. 이 경우 "통계적으로 유의미한 차이를 발견할 수 없었다($p=0.246$)"라고 기술합니다.

> ⚠️ **중요**: 이는 귀무가설(신약 효과가 없다)이 옳다는 것을 증명하는 것이 아닙니다. 단지 귀무가설을 기각하고 대립가설을 지지할 만큼의 충분한 증거를 데이터에서 찾지 못했다는 의미일 뿐입니다.

# 5.3 가설검정 관련 그래프

가설검정의 결과를 시각적으로 표현하는 그래프 작성법과 해석법에 대해 알아보겠습니다.

---

## 오차 막대 (Error Bar)

평균값을 막대그래프나 산점도로 나타낼 때는 데이터의 불확실성이나 퍼짐을 표현하기 위해 **오차 막대(error bar)**를 함께 그립니다. 오차 막대는 목적에 따라 다음 세 가지 중 하나를 사용합니다.

* **평균 ± 표준오차 (mean ± SE)**: 평균값의 불확실성(정밀도)을 나타낼 때 사용합니다. 가설검정 결과를 표현할 때 가장 일반적으로 쓰입니다.
    * 표준오차(SE, Standard Error of the Mean) = $s / \sqrt{n}$
* **95% 신뢰구간 (95% Confidence Interval)**: 평균값을 중심으로 95% 신뢰구간을 그립니다.
* **평균 ± 표준편차 (mean ± SD)**: 데이터가 퍼져있는 정도(산포도)를 나타냅니다.

> ⚠️ **중요**: 그래프를 그릴 때는 오차 막대가 위 세 가지 중 무엇을 의미하는지 **반드시 그래프 범례나 설명에 명시해야 합니다.**

*그림: 막대그래프와 산점도에 평균±표준오차(SE)를 표시한 예시*

### 오차 막대를 이용한 통계적 유의성 해석

정확한 판단은 p값을 봐야 하지만, 표준오차(SE) 막대를 통해 통계적 유의성을 대략적으로 추측할 수 있습니다.

* **표본크기($n$)가 작을 때 (예: n=3)**: 두 그룹의 오차 막대가 **2개(SE*2) 만큼** 떨어져 있어야 차이가 유의미($p<0.05$)할 가능성이 높습니다.
* **표본크기($n$)가 클 때 (예: n=10 이상)**: 두 그룹의 오차 막대 끝이 겹치지 않고 **약간만 떨어져 있어도** 유의미($p<0.05$)할 수 있습니다.

### 통계적 유의미성을 나타내는 표기

그래프나 표에서 통계적 유의미성을 간결하게 나타내기 위해 별표(asterisk)를 사용하는 것이 일반적입니다.

* `*` : $p < 0.05$
* `**` : $p < 0.01$
* `***` : $p < 0.001$
* `N.S.` (non-significant): 통계적으로 유의미하지 않음 ($p \ge 0.05$)

---
---

# 5.4 제1종 오류와 제2종 오류

가설검정에서 우리는 p값과 유의수준 $\alpha$를 비교하여 판정을 내립니다. 하지만 이 판정은 언제나 옳은 것은 아니며, 다음과 같은 두 가지 유형의 오류를 범할 수 있습니다.

## 진실과 판단의 4가지 패턴

가설검정의 판단은 실제 진실(귀무가설이 옳은지, 대립가설이 옳은지)과 조합하여 총 4가지 경우로 나눌 수 있습니다.

| | **진실: 귀무가설이 옳음** | **진실: 대립가설이 옳음** |
| :--- | :--- | :--- |
| **판단: 귀무가설 기각 안 함** | 👍 옳은 판단 (OK) | 😭 **제2종 오류 (Type II Error)** |
| **판단: 귀무가설 기각** | 😱 **제1종 오류 (Type I Error)** | 👍 옳은 판단 (OK) |

---

## 제1종 오류 (Type I Error)

> **제1종 오류**란, **실제로는 아무 차이가 없는데(귀무가설이 옳은데), 우연히 얻은 데이터만으로 차이가 있다고 잘못 결론 내리는 것**입니다. 이를 **'위양성(False Positive)'**이라고도 합니다.

제1종 오류를 범할 확률의 최댓값은 우리가 직접 설정하는 **유의수준($\alpha$)**과 같습니다. 예를 들어, 유의수준을 $\alpha = 0.05$로 설정했다는 것은, 실제 효과가 없는 20번의 실험 중 1번(5%) 정도는 "효과가 있다"고 잘못 결론 내릴 위험을 감수하겠다는 의미입니다.

## 제2종 오류 (Type II Error)와 검정력 (Power)

> **제2종 오류**란, **실제로 차이가 있는데도(대립가설이 옳은데), 데이터에서 그 차이를 발견하지 못하고 "차이가 없다"고 잘못 결론 내리는 것**입니다. 이를 **'위음성(False Negative)'**이라고도 합니다.

제2종 오류가 일어날 확률을 **$\beta$ (베타)**라고 합니다.

반대로, 실제로 차이가 있을 때 "차이가 있다!"고 올바르게 판단할 확률을 **검정력(Power of test)**이라고 하며, **$1-\beta$**로 계산합니다. 일반적으로 좋은 연구는 검정력을 80%($\beta=0.2$) 이상으로 설정합니다.

## $\alpha$와 $\beta$의 상충 관계

$\alpha$와 $\beta$는 서로 **상충 관계(trade-off)**에 있습니다. 즉, 다른 조건이 같다면 하나를 줄이면 다른 하나가 늘어납니다.
* 제1종 오류를 줄이기 위해 $\alpha$를 0.05에서 0.01로 낮추면 (더 엄격한 기준 적용), 실제로 차이가 있어도 놓치게 될 확률($\beta$)은 올라갑니다.

이 상충 관계는 **표본크기($n$)**에 따라 달라집니다. **표본크기 $n$을 늘리면 $\alpha$와 $\beta$를 동시에 줄일 수 있습니다.** 즉, 더 적은 오류로 더 정확한 판단을 할 수 있게 됩니다.

*그림: $\alpha$와 $\beta$의 상충 관계와 표본크기 $n$의 효과*

---

## 효과크기 (Effect Size)

> **효과크기(Effect size)**는 두 집단 간의 차이가 **실질적으로 얼마나 큰지**를 나타내는 표준화된 지표입니다. 표본크기와 무관하게 효과의 크기 자체를 나타냅니다.

대표적인 효과크기인 **코헨의 d(Cohen's d)**는 두 집단 평균의 차이를 표준편차로 나눈 값입니다.
$$
d = \frac{\mu_A - \mu_B}{\sigma}
$$
효과크기가 클수록 두 모집단의 분포가 더 많이 분리되며, 작은 표본으로도 차이를 쉽게 탐지할 수 있습니다.

*그림: 효과크기(d)에 따른 두 집단 분포의 겹침 정도*

### 오류, 효과크기, 표본크기의 관계

$\alpha$, $\beta$(또는 검정력 $1-\beta$), 표본크기 $n$, 효과크기 $d$는 서로 밀접하게 연관되어 있어, **이 중 3가지 값을 정하면 나머지 1개의 값이 자동으로 결정**됩니다.

연구를 설계할 때, 우리는 보통 다음을 미리 설정합니다.
1.  **유의수준 $\alpha$** (보통 0.05)
2.  **검정력 $1-\beta$** (보통 0.8 이상)
3.  **검출하고자 하는 최소한의 효과크기 $d$**

이 세 가지를 바탕으로, 해당 연구에 **필요한 적절한 표본크기 $n$을 계산**할 수 있습니다. 이를 **'검정력 분석(Power Analysis)'**이라고 합니다.
